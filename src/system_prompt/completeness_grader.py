from langchain_core.language_models.chat_models import BaseChatModel
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import Runnable, RunnableConfig
from pydantic import BaseModel, Field

from src.external_search.state import GraphState

completeness_grader_message = """
You are an expert grader with extensive knowledge in molecular biology and experience as a curator for both Reactome and UniProt knowledgebases.
Your task is to evaluate whether a response generated by an LLM is complete, meaning it addresses the userâ€™s question with necessary details, background information, and context.

Provide a binary output as either:
    - Yes: The response answers the user question and provides enough details and background. 
    - No: The response is incomplete, missing key details, or lacking sufficient context. 
"""

completeness_prompt = ChatPromptTemplate.from_messages(
    [
        ("system", completeness_grader_message),
        ("human", "User question: \n\n {input} \n\n LLM generation: {generation}"),
    ]
)


class GradeCompleteness(BaseModel):
    binary_score: str = Field(
        description="Answer is complete and provides all necessary background, 'Yes' or 'No'"
    )


class CompletenessGrader:
    def __init__(self, llm: BaseChatModel):
        structured_completeness_grader: Runnable = llm.with_structured_output(
            GradeCompleteness
        )
        self.runnable: Runnable = completeness_prompt | structured_completeness_grader

    async def ainvoke(
        self, state: GraphState, config: RunnableConfig
    ) -> dict[str, str]:
        result: GradeCompleteness = await self.runnable.ainvoke(
            {
                "input": state["input"],
                "generation": state["generation"],
            },
            config,
        )
        return {"complete": result.binary_score}
