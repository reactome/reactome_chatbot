from langchain_core.prompts import ChatPromptTemplate
from langchain_core.pydantic_v1 import BaseModel, Field
from langchain_openai import ChatOpenAI


class GradeCompleteness(BaseModel):
    """Binary score for completeness of response"""

    binary_score: str = Field(
        description="Answer is complete and provides all necessary background, 'Yes' or 'No'"
    )


llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.0)
# Initialize the structured completeness grader
structured_completeness_grader = llm.with_structured_output(GradeCompleteness)

# System message for the grader
completeness_grader_message = """
You are an expert grader with extensive knowledge in molecular biology and experience as a Reactome curator. Your task is to evaluate whether a response generated by an LLM is complete, meaning it fully addresses the userâ€™s query with all necessary details, background information, and context.

Provide a binary output as either:

Yes: The response is complete, fully answers the query, and leaves no essential details missing.
No: The response is incomplete, missing key details, or lacking sufficient context.
Ensure your evaluation is based solely on the information requested in the query and the adequacy of the response.
"""

# Define the prompt template for completeness grading
completeness_prompt = ChatPromptTemplate.from_messages(
    [
        ("system", completeness_grader_message),
        ("human", "User question: \n\n {question} \n\n LLM generation: {generation}"),
    ]
)

# Combine the prompt with the structured grader
completeness_grader = completeness_prompt | structured_completeness_grader
