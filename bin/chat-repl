#!/usr/bin/env python

import argparse
import os
from typing import Any

import pyfiglet
from dotenv import load_dotenv

from retreival_chain import initialize_retrieval_chain
from util.embedding_environment import EM_ARCHIVE, EmbeddingEnvironment


async def main() -> None:
    load_dotenv()

    parser = argparse.ArgumentParser(description="Reactome ChatBot")
    parser.add_argument("--openai-key", help="API key for OpenAI")
    parser.add_argument("--query", help="Query string to run")
    parser.add_argument("--verbose", action="store_true", help="Enable verbose mode")
    parser.add_argument(
        "--ollama-model", help="Ollama language model to use (alternative to OpenAI)"
    )
    parser.add_argument(
        "--ollama-url", default="http://localhost:11434", help="Ollama host url"
    )
    parser.add_argument(
        "--hf-model",
        help="HuggingFace sentence_transformers model (alternative to OpenAI)",
    )
    parser.add_argument(
        "--hf-key",
        help="API key for HuggingFaceHub",
    )
    parser.add_argument(
        "--device",
        default="cpu",
        help="PyTorch device to use when running HuggingFace embeddings locally [cpu/cuda]",
    )
    args = parser.parse_args()

    if args.openai_key:
        os.environ["OPENAI_API_KEY"] = args.openai_key

    if args.hf_key:
        os.environ["HUGGINGFACEHUB_API_TOKEN"] = args.hf_key

    env = os.getenv("CHAT_ENV", "reactome")
    embeddings_directory = EM_ARCHIVE / EmbeddingEnvironment.get_dict()[env]

    qa = initialize_retrieval_chain(
        env
        embeddings_directory,
        True,
        args.verbose,
        args.ollama_model,
        args.ollama_url,
        args.hf_model,
        args.device,
    )
    if args.query:
        await print_results(qa, args.query, args.verbose)
    else:
        await interactive_mode(qa, args.verbose)


async def interactive_mode(qa: Any, verbose: bool) -> None:
    reactome_figlet = pyfiglet.figlet_format("React-to-me")
    print(reactome_figlet)
    print(
        "Reactome Chatbot instructions: After each response you will have an opportunity to ask another questions. If you are done type enter instead of a question to exit."
    )
    while True:
        query: str = input("\n\nUser Query:")
        if not query:
            break
        print("\nResponse:")
        await print_results(qa, query, verbose)


async def print_results(qa: Any, query: str, verbose: bool) -> None:
    async for qa_result in qa.invoke(query):
        pass


if __name__ == "__main__":
    import asyncio

    asyncio.run(main())
